# Default values for artifactory-ha.
# This is a YAML-formatted file.
# Beware when changing values here. You should know what you are doing!
# Access the values with {{ .Values.key.subkey }}

## You likely don't want to touch this unless you are using your own kintohub images
## This is the name of the registry in docker hub
## ie: kintohub/kinto-core:latest
repo: kintohub

common:
  ssl:
    enabled: false
    ## Cert Manager concept: https://cert-manager.io/docs/concepts/issuer/
    ## This issuer is cluster wide and will be used for every cert generated in KintoHub
    ## Issuer only works with cloudflare at the moment, please create an issue or open a PR if you want to add more
    ## Here are the list of providers supported: https://cert-manager.io/docs/configuration/acme/dns01/#supported-dns01-providers    
    issuer:
      email: devaccounts@kintohub.com ## TO BE CHANGED - this email will be used for every certificate generated
      server: https://acme-v02.api.letsencrypt.org/directory ## let's encrypt server used (this is the production one)
      solver:
        ## Generate a token using https://cert-manager.io/docs/configuration/acme/dns01/cloudflare/#api-tokens
        ## No need to provide `cloudflareApiToken` if `existingSecret` is set
        # existingSecret: kinto-cert-manager ## in `cert-manager` namespace
        cloudflare:
          email: devaccounts@kintohub.com ## TO BE CHANGED - your cloudflare username account
          cloudflareApiToken: j5Z0t1sBXDzGiOlUNtHmr2POyXUhatdDD_uk8XhC ## TO BE CHANGED

    certificate:
      ## Common wildcard certficate used for all web servers exposed external on kintohub
      ## ie: the url to access your service will be https://[something].oss.kintohub.net
      dnsName: "*.oss.kintohub.net" ## TO BE CHANGED

core:
  replicas: 1

  image: kinto-core:latest
  imagePullPolicy: Always

  grpc:
    port: 8080

  grpcWeb:
    port: 8090

  ingress:
    ## Disable this if you don't want kinto-core to be exposed on internet
    enabled: true
    grpc:
      ## External host name used by kinto-cli to connect to kinto-core
      host: core.oss.kintohub.net ## TO BE CHANGED
    grpcWeb:
      ## External host name used by kinto-dashboard to connect to kinto-core
      host: core-web.oss.kintohub.net ## TO BE CHANGED

  env:
    LOG_LEVEL: DEBUG
    ## All web servers will be exposed with a subdomain of KINTO_DOMAIN
    ## must be the same as `common.ssl.certificate.dnsName` minus `*.`
    KINTO_DOMAIN: "oss.kintohub.net" ## TO BE CHANGED
  
  resources: {}

builder:
  replicas: 1

  image: kinto-builder
  imagePullPolicy: Always
  tag: latest

  port: 8080

  env:
    LOG_LEVEL: DEBUG

    ## Image Registry used to push images that are built using KintoHub
    ## In order for kintohub to gain access over this registry, you must configure `builder.workflow.docker` correctly.
    IMAGE_REGISTRY_HOST: eu.gcr.io/kinto-development ## TO BE CHANGED

    POLL_LOGS_INTERVAL_SECONDS: 1
    USER_FRIENDLY_BUILD_LOGS_ENABLED: false 

    ## Timeout in seconds after which the workflow fails
    WORKFLOW_TIMEOUT: 1800

    ## Configuration for Argo Workflow. KintoHub generated Argo Workflow in Kubernetes to build and deploy your services.
    ## Therefore, workflows must be configured according to what you build.
    ARGO_WORKFLOW_TTL_SECONDS: 120 ## After completion, Argo automatically clean up kubernetes and delete the workflow after ARGO_WORKFLOW_TTL_SECONDS in seconds
    ARGO_WORKFLOW_MINIO_HOST: kinto-minio:9000
    ARGO_WORKFLOW_MINIO_BUCKET: argo-artifacts
    ARGO_WORKFLOW_IMAGE_PULL_POLICY: IfNotPresent
    ARGO_WORKFLOW_VOLUME_SIZE: 1Gi ## each workflow used a private volume.
    ARGO_WORKFLOW_MEMORY_LIMIT: 4Gi
    ARGO_WORKFLOW_CPU_LIMIT: 2

  resources: {}

  workflow:
    mainImage: kinto-workflow-main ## don't add tag here, it is dependant of `builder.tag`
    cliImage: kinto-workflow-cli ## don't add tag here, it is dependant of `builder.tag`

    ## Docker registry to access `builder.env.IMAGE_REGISTRY_HOST`
    ## This will create a type `kubernetes.io/dockerconfigjson` secret in kubernetes
    docker: ## TO BE CHANGED
      ## No need to provide the rest of the information if `existingSecret` is set
      # existingSecret: kinto-builder-workflow-docker ## in `kintohub` namespace
      ## Using GCR
      registry: eu.gcr.io
      email: devaccounts@kintohub.com
      username: _json_key
      password: '{
  "type": "service_account",
  "project_id": "kinto-development",
  "private_key_id": "9172aa92e5db9ee5f1e4301b91d73d461e1ee03f",
  "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDNLraxpMZjzFBm\niruFxuxeD6kJ99pvm2Zg77Sl52VQ7ftzKWbivcW4ljQjaktMHzqQm0mRRnn6127+\nLXiBUlI53BGPJTZ0mGxlMRmOsuYfj3Mqstf6FCTNQVYMmlu/9gkpzWev3Is1GXEC\nxXI/1KWwXPnlpdOl19lyPuSBS+fmEDjTnZNHFJDCFmJkL/l/wkn2qvu2jp0GSzb4\nIB6lbMB0XczYnFx8wVLzA/sZ78x0zWxyw37Yx4en5pUbmgWUcympK0Oce/4XoxDp\nK01pY3FzMGSQrrvSIcacHVY79PI27sID7py5BLp/exxNwQ66qLtBIu9Gfj/WFpJp\n2n5abd4/AgMBAAECggEACCPaS6Hl3P+2ENtgJSaHKhQk+KhEmjjoDuBzokFT26oV\nV7REyKoOtgv/dYg6BIMYp7QBbyoEnNb/KEZViYvihzkb2Tn4txd09W7FPMwMJSRj\nxUXjG6DA9QOqjkVxbmQsaOQlQOzW+PxRZ3K93ZpqGF0X7OxvQR0XG1kzZ43DXXUl\nFlSEAdcPMkIMpy9y0SWthPpguGo92Qlg8EejdVzKgmULnk0L2U4GVBdXr0f2RC3C\nyfClq2g69hCHvXyr1cJoHPB5MCFJbDnhnxCyqcJXlN60PV2LtBVzWLVnhTITuAuW\npz4uXqTsOuSnqb0dueshov2oU0oDOAeYjUwmqwR4AQKBgQDxbr2x5/Hl414Sm+s+\niAmvJm5Ba33J8X8B5hmEnFN5/bu1ycw7IgIdl9coNTz6RqNRMI0s1UNWCh4OARuJ\n73TXkHMkcTsCgpKNwGoEiWpTAEVPF4OmOwzu+0xSCgia0g1xTlw7dgtLku6VDln7\nwuBmTeiMq+quo3l/Bf1ZS7a+gQKBgQDZkAovg9riqpwP246Thj6kyrvF1Wht7xCK\nw/zIBFkXSDQCP5WhH3xKal7dRNTu6tBpRQZPQGAe4S5bMB13d3r8TW/WpFCVbVrE\nccg0JykJQkALns0+Y8SNxDBN+2pIOAzEOKPxuM3TxEocR5jAWvKEZYNQZMh9TefZ\naCB+76+8vwKBgQDxQ1v3M7TsqQhyCjPL+j/LMtlNMLC0JEtqR1nKxjk5GBEDudQI\nZ5S7o+fTe1gjNoGv+ZeqbLdsfJHKJtsxPQSDAgu+KBTzDi6LzvNi8zs4FHYucm4R\nqMLk8mUzOmmc5Tmft9G9bdodvIgEliHfz79VHJe+M3JC8IPSJtck69+DgQKBgEvc\nkfCnhXdsDibpY/nE4asMlhURqOxMY/Q/CrGj8nzPzHLMQRyBohFArftxuN3mOu26\nB80yoVGjK0rYqC20F8pKJikt+ntgOjotgqXM0d5Mn5Btuxt6JltYgY9vj0vHX4w8\nQ85RplOlKkJaJMVN8SqBSxyJR++JbsK8MDiS0zB5AoGAEhK+a/o0v3TIs3nnwWlN\nadFUTRj5QO6jsnhnw+Y/BzJ8NrBj3NFkovk1fTMBiQJCSICNc5KRbUNYpHxWNHK/\n9Q2RK0ZTJnkH30wNzfwksoOC6GJYYQ9UOPuN4d3D5BBD0qKdXOcffX1tKO6BmXL0\nRn75q+u865rcSP9jn8DfHRY=\n-----END PRIVATE KEY-----\n",
  "client_email": "temporary-gcs-admin@kinto-development.iam.gserviceaccount.com",
  "client_id": "106217820440723117186",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/temporary-gcs-admin%40kinto-development.iam.gserviceaccount.com"
}'
      ## Using Dockerhub
      # Right not kaniko doesn't support v2 API
      # https://github.com/GoogleContainerTools/kaniko/issues/1209
      # registry: https://index.docker.io/v1/
      # email: devaccounts@kintohub.com
      # username: kintohub
      # password: [DOCKERHUB-API-TOKEN] # Create access token https://docs.docker.com/docker-hub/access-tokens/

dashboard:
  replicas: 1

  image: kinto-dashboard:latest
  imagePullPolicy: Always

  port: 5000

  resources: {}

  ingress:
    ## Disable this if you don't want kinto-dashboard to be exposed on internet
    enabled: true
    ## User will open this URL on their browser to access the dashboard
    host: dashboard.oss.kintohub.net ## TO BE CHANGED

  env:
    REACT_APP_GRPC_WEB_HTTPS_ENABLED: true
    REACT_APP_SLEEP_MODE_TTL_MINUTES: "10" ## Default Time To Sleep for web servers configured with Sleep Mode enabled
    REACT_APP_LOCAL_STORAGE_VERSION: "20201124153800"

## Configuration for nginx-ingress-controller
## KintoHub as well as all your webservers with public access will be exposed throught this nginx controller
nginx-ingress-controller:
  service:
    ##  PR : https://github.com/kintohub/kinto-kube-infra/pull/65
    ##  This is for preserving client IP address
    ##
    ##  Plz take extra care of the information below.
    ##
    ##  The proper way to fix that should have been to enable "proxy protocol" on the nginx ingress controller.
    ##  Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-proxy-protocol
    ##
    ##  However, this is not supported by GCP/GKE. Ref: https://kubernetes.github.io/ingress-nginx/deploy/#gce-gke
    ##  (It is however supported by AWS, DO, maybe Azure? - anyway, quite surprising)
    ##
    ##  So I ended up setting externalTrafficPolicy of our nginx ingress ingress service to Local instead of Cluster.
    ##  Ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##  However, it has the downside of not balancing the traffic very well. Indeed the LB will still target multiple nodes, but they will
    ##  not take into consideration the number of pods per nodes.
    ##  See following video: https://www.youtube.com/watch?v=y2bhV81MfKQ&feature=youtu.be&t=1823
    ##  As u can see, this downside will mostly be for multiple pods of the same deployment per node. And our user don't have this case yet,
    ##  they barely use autoscaling.
    ##  So I suggest we merge this PR and we will see in the future if issue arises. We will be able then to maybe deploy another ingress 
    ##  controller with better spreading.
    externalTrafficPolicy: Local

  replicaCount: 1
  minAvailable: 1

  config:
    proxy-body-size: "50m"

  resources: {}

  scope:
    enabled: false
  
  extraArgs:
    ## Wildcard certificate corresponding to `common.ssl.certificate`
    ## All your webservers will use this certificate by default
    ## /!\ CHANGE THIS IF NAMESPACE != "kintohub"
    default-ssl-certificate: "kintohub/common-wildcard-cert"

  defaultBackend:
    replicaCount: 1
    minAvailable: 1

    resources: {}

## Configuration for proxless
## Proxless is used for Sleep mode
## Reference: https://github.com/bappr/proxless
proxless:
  port: 80

  image:
    repository: bappr/proxless
    tag: v0.1.7
    pullPolicy: Always

  logLevel: DEBUG
  replicas: 1 ## Uncomment `REDIS_URL` if > 1 and change `redis.enabled` to `true`

  resources: {}

  env:
    SERVERLESS_TTL_SECONDS: 30 # Time in seconds proxless waits before scaling down the app
    DEPLOYMENT_READINESS_TIMEOUT_SECONDS: 30 # Time in seconds proxless waits for the deployment to be ready when scaling up the app
    SCALE_DOWN_CHECK_INTERVAL_SECONDS: 3000 # The downscaler check the deployment every N seconds
    SERVICES_INFORMER_RESYNC_INTERVAL_SECONDS: 3000 # All services will be resynced after N seconds
    # REDIS_URL: kinto-redis-master:6379 # Configured to use redis below

  redis:
    enabled: false

## Configuration for minio
## Minio used to store the history of deployment logs
minio:
  accessKey: "AKIAIOSFODNN7EXAMPLE"
  secretKey: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"

  persistence:
    enabled: true
    size: 10Gi

  resources:
    requests: null ## https://github.com/helm/helm/issues/1966

  defaultBucket:
    enabled: true
    name: argo-artifacts

  environment:
    MINIO_API_READY_DEADLINE: "5s"
    MINIO_BROWSER: "on"